
@misc{duval_hitchhikers_2024,
	title = {A {Hitchhiker}'s {Guide} to {Geometric} {GNNs} for {3D} {Atomic} {Systems}},
	url = {http://arxiv.org/abs/2312.07511},
	doi = {10.48550/arXiv.2312.07511},
	abstract = {Recent advances in computational modelling of atomic systems, spanning molecules, proteins, and materials, represent them as geometric graphs with atoms embedded as nodes in 3D Euclidean space. In these graphs, the geometric attributes transform according to the inherent physical symmetries of 3D atomic systems, including rotations and translations in Euclidean space, as well as node permutations. In recent years, Geometric Graph Neural Networks have emerged as the preferred machine learning architecture powering applications ranging from protein structure prediction to molecular simulations and material generation. Their specificity lies in the inductive biases they leverage — such as physical symmetries and chemical properties — to learn informative representations of these geometric graphs.},
	language = {en},
	urldate = {2025-11-20},
	publisher = {arXiv},
	author = {Duval, Alexandre and Mathis, Simon V. and Joshi, Chaitanya K. and Schmidt, Victor and Miret, Santiago and Malliaros, Fragkiskos D. and Cohen, Taco and Liò, Pietro and Bengio, Yoshua and Bronstein, Michael},
	month = mar,
	year = {2024},
	note = {arXiv:2312.07511 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Quantitative Biology - Quantitative Methods, Statistics - Machine Learning},
	file = {PDF:/Users/shreyas/Zotero/storage/236P3JRK/Duval et al. - 2024 - A Hitchhiker's Guide to Geometric GNNs for 3D Atomic Systems.pdf:application/pdf},
}

@article{carilli_biophysical_2024,
	title = {Biophysical modeling with variational autoencoders for bimodal, single-cell {RNA} sequencing data},
	volume = {21},
	copyright = {2024 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/s41592-024-02365-9},
	doi = {10.1038/s41592-024-02365-9},
	abstract = {Here we present biVI, which combines the variational autoencoder framework of scVI with biophysical models describing the transcription and splicing kinetics of RNA molecules. We demonstrate on simulated and experimental single-cell RNA sequencing data that biVI retains the variational autoencoder’s ability to capture cell type structure in a low-dimensional space while further enabling genome-wide exploration of the biophysical mechanisms, such as system burst sizes and degradation rates, that underlie observations.},
	language = {en},
	number = {8},
	urldate = {2025-11-23},
	journal = {Nature Methods},
	author = {Carilli, Maria and Gorin, Gennady and Choi, Yongin and Chari, Tara and Pachter, Lior},
	month = aug,
	year = {2024},
	note = {Publisher: Nature Publishing Group},
	keywords = {Machine learning, Data integration, Software, Transcriptomics},
	pages = {1466--1469},
	file = {Full Text PDF:/Users/shreyas/Zotero/storage/RS95VGUW/Carilli et al. - 2024 - Biophysical modeling with variational autoencoders for bimodal, single-cell RNA sequencing data.pdf:application/pdf},
}

@misc{noauthor_proteingym_nodate,
	title = {{ProteinGym}},
	url = {https://proteingym.org/},
	urldate = {2025-11-23},
	file = {ProteinGym:/Users/shreyas/Zotero/storage/7Y7Y6VKA/proteingym.org.html:text/html},
}

@misc{dallago_flip_2021,
	title = {{FLIP}: {Benchmark} tasks in fitness landscape inference for proteins},
	shorttitle = {{FLIP}},
	url = {http://biorxiv.org/lookup/doi/10.1101/2021.11.09.467890},
	doi = {10.1101/2021.11.09.467890},
	abstract = {Machine learning could enable an unprecedented level of control in protein engineering for therapeutic and industrial applications. Critical to its use in designing proteins with desired properties, machine learning models must capture the protein sequence-function relationship, often termed ﬁtness landscape. Existing benchmarks like CASP or CAFA assess structure and function predictions of proteins, respectively, yet they do not target metrics relevant for protein engineering. In this work, we introduce Fitness Landscape Inference for Proteins (FLIP), a benchmark for function prediction to encourage rapid scoring of representation learning for protein engineering. Our curated tasks, baselines, and metrics probe model generalization in settings relevant for protein engineering, e.g. low-resource and extrapolative. Currently, FLIP encompasses experimental data across adeno-associated virus stability for gene therapy, protein domain B1 stability and immunoglobulin binding, and thermostability from multiple protein families. In order to enable ease of use and future expansion to new tasks, all data are presented in a standard format. FLIP scripts and data are freely accessible at https://benchmark.protein.properties.},
	language = {en},
	urldate = {2025-11-23},
	publisher = {Bioengineering},
	author = {Dallago, Christian and Mou, Jody and Johnston, Kadina E. and Wittmann, Bruce J. and Bhattacharya, Nicholas and Goldman, Samuel and Madani, Ali and Yang, Kevin K.},
	month = nov,
	year = {2021},
	file = {PDF:/Users/shreyas/Zotero/storage/RHES2RC2/Dallago et al. - 2021 - FLIP Benchmark tasks in fitness landscape inference for proteins.pdf:application/pdf},
}

@misc{notin_proteingym_2023,
	title = {{ProteinGym}: {Large}-{Scale} {Benchmarks} for {Protein} {Design} and {Fitness} {Prediction}},
	shorttitle = {{ProteinGym}},
	url = {http://biorxiv.org/lookup/doi/10.1101/2023.12.07.570727},
	doi = {10.1101/2023.12.07.570727},
	abstract = {Predicting the effects of mutations in proteins is critical to many applications, from understanding genetic disease to designing novel proteins that can address our most pressing challenges in climate, agriculture and healthcare. Despite a surge in machine learning-based protein models to tackle these questions, an assessment of their respective benefits is challenging due to the use of distinct, often contrived, experimental datasets, and the variable performance of models across different protein families. Addressing these challenges requires scale. To that end we introduce ProteinGym, a large-scale and holistic set of benchmarks specifically designed for protein fitness prediction and design. It encompasses both a broad collection of over 250 standardized deep mutational scanning assays, spanning millions of mutated sequences, as well as curated clinical datasets providing highquality expert annotations about mutation effects. We devise a robust evaluation framework that combines metrics for both fitness prediction and design, factors in known limitations of the underlying experimental methods, and covers both zero-shot and supervised settings. We report the performance of a diverse set of over 70 high-performing models from various subfields (eg., alignment-based, inverse folding) into a unified benchmark suite. We open source the corresponding codebase, datasets, MSAs, structures, model predictions and develop a user-friendly website that facilitates data access and analysis.},
	language = {en},
	urldate = {2025-11-23},
	publisher = {Synthetic Biology},
	author = {Notin, Pascal and Kollasch, Aaron W. and Ritter, Daniel and Van Niekerk, Lood and Paul, Steffanie and Spinner, Hansen and Rollins, Nathan and Shaw, Ada and Weitzman, Ruben and Frazer, Jonathan and Dias, Mafalda and Franceschi, Dinko and Orenbuch, Rose and Gal, Yarin and Marks, Debora S.},
	month = dec,
	year = {2023},
	file = {PDF:/Users/shreyas/Zotero/storage/I7HTYXGS/Notin et al. - 2023 - ProteinGym Large-Scale Benchmarks for Protein Design and Fitness Prediction.pdf:application/pdf},
}

@misc{noauthor_navigating_nodate,
	title = {Navigating the protein fitness landscape with {Gaussian} processes},
	url = {https://www.pnas.org/doi/10.1073/pnas.1215251110},
	language = {en},
	urldate = {2025-11-23},
	doi = {10.1073/pnas.1215251110},
	file = {Full Text PDF:/Users/shreyas/Zotero/storage/36N3EHUJ/Navigating the protein fitness landscape with Gaussian processes.pdf:application/pdf;Snapshot:/Users/shreyas/Zotero/storage/VJWXWKJ9/pnas.html:text/html},
}

@article{gorin_rna_2022,
	title = {{RNA} velocity unraveled},
	volume = {18},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010492},
	doi = {10.1371/journal.pcbi.1010492},
	abstract = {We perform a thorough analysis of RNA velocity methods, with a view towards understanding the suitability of the various assumptions underlying popular implementations. In addition to providing a self-contained exposition of the underlying mathematics, we undertake simulations and perform controlled experiments on biological datasets to assess workflow sensitivity to parameter choices and underlying biology. Finally, we argue for a more rigorous approach to RNA velocity, and present a framework for Markovian analysis that points to directions for improvement and mitigation of current problems.},
	language = {en},
	number = {9},
	urldate = {2025-11-24},
	journal = {PLOS Computational Biology},
	author = {Gorin, Gennady and Fang, Meichen and Chari, Tara and Pachter, Lior},
	month = sep,
	year = {2022},
	note = {Publisher: Public Library of Science},
	keywords = {Biophysics, DNA transcription, Mammalian genomics, Messenger RNA, RNA sequencing, Simulation and modeling, Transcriptome analysis, Velocity},
	pages = {e1010492},
	file = {Full Text PDF:/Users/shreyas/Zotero/storage/YHPIEFUQ/Gorin et al. - 2022 - RNA velocity unraveled.pdf:application/pdf},
}

@article{greenman_benchmarking_2025,
	title = {Benchmarking uncertainty quantification for protein engineering},
	volume = {21},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1012639},
	doi = {10.1371/journal.pcbi.1012639},
	abstract = {Machine learning sequence-function models for proteins could enable significant advances in protein engineering, especially when paired with state-of-the-art methods to select new sequences for property optimization and/or model improvement. Such methods (Bayesian optimization and active learning) require calibrated estimations of model uncertainty. While studies have benchmarked a variety of deep learning uncertainty quantification (UQ) methods on standard and molecular machine-learning datasets, it is not clear if these results extend to protein datasets. In this work, we implemented a panel of deep learning UQ methods on regression tasks from the Fitness Landscape Inference for Proteins (FLIP) benchmark. We compared results across different degrees of distributional shift using metrics that assess each UQ method’s accuracy, calibration, coverage, width, and rank correlation. Additionally, we compared these metrics using one-hot encoding and pretrained language model representations, and we tested the UQ methods in retrospective active learning and Bayesian optimization settings. Our results indicate that there is no single best UQ method across all datasets, splits, and metrics, and that uncertainty-based sampling is often unable to outperform greedy sampling in Bayesian optimization. These benchmarks enable us to provide recommendations for more effective design of biological sequences using machine learning.},
	language = {en},
	number = {1},
	urldate = {2025-11-24},
	journal = {PLOS Computational Biology},
	author = {Greenman, Kevin P. and Amini, Ava P. and Yang, Kevin K.},
	month = jan,
	year = {2025},
	note = {Publisher: Public Library of Science},
	keywords = {Machine learning, Antibodies, Data acquisition, Extrapolation, Language, Optimization, Protein domains, Protein engineering},
	pages = {e1012639},
	file = {Full Text PDF:/Users/shreyas/Zotero/storage/WB26ALVV/Greenman et al. - 2025 - Benchmarking uncertainty quantification for protein engineering.pdf:application/pdf},
}

@article{dong_pcc_nodate,
	title = {{PCC} {Vivace}: {Online}-{Learning} {Congestion} {Control}},
	abstract = {TCP’s congestion control architecture suffers from notoriously bad performance. Consequently, recent years have witnessed a surge of interest in both academia and industry in novel approaches to congestion control. We show, however, that past approaches fall short of attaining ideal performance. We leverage ideas from the rich literature on online (convex) optimization in machine learning to design Vivace, a novel rate-control protocol, designed within the recently proposed PCC framework. Our theoretical and experimental analyses establish that Vivace signiﬁcantly outperforms traditional TCP variants, the previous realization of the PCC framework, and BBR in terms of performance (throughput, latency, loss), convergence speed, alleviating bufferbloat, reactivity to changing network conditions, and friendliness towards legacy TCP in a range of scenarios. Vivace requires only sender-side changes and is thus readily deployable.},
	language = {en},
	author = {Dong, Mo and Meng, Tong and Zarchy, Doron and Arslan, Engin and Gilad, Yossi and Godfrey, Brighten and Schapira, Michael},
	file = {PDF:/Users/shreyas/Zotero/storage/ZRNXBJSF/Dong et al. - PCC Vivace Online-Learning Congestion Control.pdf:application/pdf},
}

@article{dong_pcc_nodate-1,
	title = {{PCC} {Vivace}: {Online}-{Learning} {Congestion} {Control}},
	abstract = {TCP’s congestion control architecture suffers from notoriously bad performance. Consequently, recent years have witnessed a surge of interest in both academia and industry in novel approaches to congestion control. We show, however, that past approaches fall short of attaining ideal performance. We leverage ideas from the rich literature on online (convex) optimization in machine learning to design Vivace, a novel rate-control protocol, designed within the recently proposed PCC framework. Our theoretical and experimental analyses establish that Vivace signiﬁcantly outperforms traditional TCP variants, the previous realization of the PCC framework, and BBR in terms of performance (throughput, latency, loss), convergence speed, alleviating bufferbloat, reactivity to changing network conditions, and friendliness towards legacy TCP in a range of scenarios. Vivace requires only sender-side changes and is thus readily deployable.},
	language = {en},
	author = {Dong, Mo and Meng, Tong and Zarchy, Doron and Arslan, Engin and Gilad, Yossi and Godfrey, Brighten and Schapira, Michael},
	file = {PDF:/Users/shreyas/Zotero/storage/JA49C39C/Dong et al. - PCC Vivace Online-Learning Congestion Control.pdf:application/pdf},
}

@article{dong_pcc_nodate-2,
	title = {{PCC} {Vivace}: {Online}-{Learning} {Congestion} {Control}},
	abstract = {TCP’s congestion control architecture suffers from notoriously bad performance. Consequently, recent years have witnessed a surge of interest in both academia and industry in novel approaches to congestion control. We show, however, that past approaches fall short of attaining ideal performance. We leverage ideas from the rich literature on online (convex) optimization in machine learning to design Vivace, a novel rate-control protocol, designed within the recently proposed PCC framework. Our theoretical and experimental analyses establish that Vivace signiﬁcantly outperforms traditional TCP variants, the previous realization of the PCC framework, and BBR in terms of performance (throughput, latency, loss), convergence speed, alleviating bufferbloat, reactivity to changing network conditions, and friendliness towards legacy TCP in a range of scenarios. Vivace requires only sender-side changes and is thus readily deployable.},
	language = {en},
	author = {Dong, Mo and Meng, Tong and Zarchy, Doron and Arslan, Engin and Gilad, Yossi and Godfrey, Brighten and Schapira, Michael},
	file = {PDF:/Users/shreyas/Zotero/storage/2Q8UIXB3/Dong et al. - PCC Vivace Online-Learning Congestion Control.pdf:application/pdf},
}

@inproceedings{costa_r2c2_2015,
	address = {London United Kingdom},
	title = {{R2C2}: {A} {Network} {Stack} for {Rack}-scale {Computers}},
	isbn = {978-1-4503-3542-3},
	shorttitle = {{R2C2}},
	url = {https://dl.acm.org/doi/10.1145/2785956.2787492},
	doi = {10.1145/2785956.2787492},
	abstract = {Rack-scale computers, comprising a large number of microservers connected by a direct-connect topology, are expected to replace servers as the building block in data centers. We focus on the problem of routing and congestion control across the rack’s network, and ﬁnd that high path diversity in rack topologies, in combination with workload diversity across it, means that traditional solutions are inadequate.},
	language = {en},
	urldate = {2025-11-25},
	booktitle = {Proceedings of the 2015 {ACM} {Conference} on {Special} {Interest} {Group} on {Data} {Communication}},
	publisher = {ACM},
	author = {Costa, Paolo and Ballani, Hitesh and Razavi, Kaveh and Kash, Ian},
	month = aug,
	year = {2015},
	pages = {551--564},
	file = {PDF:/Users/shreyas/Zotero/storage/WKPJKS5H/Costa et al. - 2015 - R2C2 A Network Stack for Rack-scale Computers.pdf:application/pdf},
}

@misc{outlier_flow_2025,
	title = {Flow {Matching} {\textbar} {Explanation} + {PyTorch} {Implementation}},
	url = {https://www.youtube.com/watch?v=7cMzfkWFWhI},
	abstract = {In this video we look at Flow Matching, a big simplification to traditional Diffusion Models. This video covers one very simple intuitive explanation + the derivation that is shown in the paper. I highly recommend you take a look at the simple intuitive explanation because this comprises only 2 formulas. 

Code: https://github.com/dome272/Flow-Matching

00:00 Intro 
01:29 Introduction 
02:33 Intuitive Derivation
05:44 Flow Matching in the bigger picture of Diffusion Models 
06:39 Derivation
17:06 PyTorch Implementation 

Further Reading: 
Flow Matching: https://arxiv.org/abs/2210.02747
Movie Gen: https://arxiv.org/abs/2410.13720
Stable Diffusion 3: https://arxiv.org/abs/2403.03206

\#flux \#diffusion \#diffusionmodels \#flowmatching \#moviegen \#pytorch},
	urldate = {2025-12-21},
	author = {{Outlier}},
	month = jan,
	year = {2025},
}

@misc{lipman_flow_2023,
	title = {Flow {Matching} for {Generative} {Modeling}},
	url = {http://arxiv.org/abs/2210.02747},
	doi = {10.48550/arXiv.2210.02747},
	abstract = {We introduce a new paradigm for generative modeling built on Continuous Normalizing Flows (CNFs), allowing us to train CNFs at unprecedented scale. Specifically, we present the notion of Flow Matching (FM), a simulation-free approach for training CNFs based on regressing vector fields of fixed conditional probability paths. Flow Matching is compatible with a general family of Gaussian probability paths for transforming between noise and data samples -- which subsumes existing diffusion paths as specific instances. Interestingly, we find that employing FM with diffusion paths results in a more robust and stable alternative for training diffusion models. Furthermore, Flow Matching opens the door to training CNFs with other, non-diffusion probability paths. An instance of particular interest is using Optimal Transport (OT) displacement interpolation to define the conditional probability paths. These paths are more efficient than diffusion paths, provide faster training and sampling, and result in better generalization. Training CNFs using Flow Matching on ImageNet leads to consistently better performance than alternative diffusion-based methods in terms of both likelihood and sample quality, and allows fast and reliable sample generation using off-the-shelf numerical ODE solvers.},
	urldate = {2025-12-21},
	publisher = {arXiv},
	author = {Lipman, Yaron and Chen, Ricky T. Q. and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matt},
	month = feb,
	year = {2023},
	note = {arXiv:2210.02747 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Preprint PDF:/Users/shreyas/Zotero/storage/W549G4T7/Lipman et al. - 2023 - Flow Matching for Generative Modeling.pdf:application/pdf},
}

@misc{lipman_flow_2023-1,
	title = {Flow {Matching} for {Generative} {Modeling}},
	url = {http://arxiv.org/abs/2210.02747},
	doi = {10.48550/arXiv.2210.02747},
	abstract = {We introduce a new paradigm for generative modeling built on Continuous Normalizing Flows (CNFs), allowing us to train CNFs at unprecedented scale. Speciﬁcally, we present the notion of Flow Matching (FM), a simulation-free approach for training CNFs based on regressing vector ﬁelds of ﬁxed conditional probability paths. Flow Matching is compatible with a general family of Gaussian probability paths for transforming between noise and data samples—which subsumes existing diffusion paths as speciﬁc instances. Interestingly, we ﬁnd that employing FM with diffusion paths results in a more robust and stable alternative for training diffusion models. Furthermore, Flow Matching opens the door to training CNFs with other, non-diffusion probability paths. An instance of particular interest is using Optimal Transport (OT) displacement interpolation to deﬁne the conditional probability paths. These paths are more efﬁcient than diffusion paths, provide faster training and sampling, and result in better generalization. Training CNFs using Flow Matching on ImageNet leads to consistently better performance than alternative diffusion-based methods in terms of both likelihood and sample quality, and allows fast and reliable sample generation using off-the-shelf numerical ODE solvers.},
	language = {en},
	urldate = {2025-12-21},
	publisher = {arXiv},
	author = {Lipman, Yaron and Chen, Ricky T. Q. and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matt},
	month = feb,
	year = {2023},
	note = {arXiv:2210.02747 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {PDF:/Users/shreyas/Zotero/storage/R8RFIGSB/Lipman et al. - 2023 - Flow Matching for Generative Modeling.pdf:application/pdf},
}

@article{lipman_flow_nodate,
	title = {Flow {Matching} {Guide} and {Code}},
	language = {en},
	author = {Lipman, Yaron and Havasi, Marton and Holderrieth, Peter and Shaul, Neta and Le, Matt and Karrer, Brian and Chen, Ricky T Q and Lopez-Paz, David and Ben-Hamu, Heli and Gat, Itai},
	file = {PDF:/Users/shreyas/Zotero/storage/4T4LMI8M/Lipman et al. - Flow Matching Guide and Code.pdf:application/pdf},
}

@misc{hoogeboom_equivariant_2022,
	title = {Equivariant {Diffusion} for {Molecule} {Generation} in {3D}},
	url = {http://arxiv.org/abs/2203.17003},
	doi = {10.48550/arXiv.2203.17003},
	abstract = {This work introduces a diffusion model for molecule generation in 3D that is equivariant to Euclidean transformations. Our E(3) Equivariant Diffusion Model (EDM) learns to denoise a diffusion process with an equivariant network that jointly operates on both continuous (atom coordinates) and categorical features (atom types). In addition, we provide a probabilistic analysis which admits likelihood computation of molecules using our model. Experimentally, the proposed method signiﬁcantly outperforms previous 3D molecular generative methods regarding the quality of generated samples and efﬁciency at training time.},
	language = {en},
	urldate = {2025-12-23},
	publisher = {arXiv},
	author = {Hoogeboom, Emiel and Satorras, Victor Garcia and Vignac, Clément and Welling, Max},
	month = jun,
	year = {2022},
	note = {arXiv:2203.17003 [cs]},
	keywords = {Computer Science - Machine Learning, Quantitative Biology - Quantitative Methods, Statistics - Machine Learning},
	annote = {Comment: Accepted at International Conference on Machine Learning (ICML) 2022},
	file = {PDF:/Users/shreyas/Zotero/storage/475IJDQY/Hoogeboom et al. - 2022 - Equivariant Diffusion for Molecule Generation in 3D.pdf:application/pdf},
}

@misc{dunn_mixed_2024,
	title = {Mixed {Continuous} and {Categorical} {Flow} {Matching} for {3D} {De} {Novo} {Molecule} {Generation}},
	url = {http://arxiv.org/abs/2404.19739},
	doi = {10.48550/arXiv.2404.19739},
	abstract = {Deep generative models that produce novel molecular structures have the potential to facilitate chemical discovery. Diffusion models currently achieve state of the art performance for 3D molecule generation. In this work, we explore the use of flow matching, a recently proposed generative modeling framework that generalizes diffusion models, for the task of de novo molecule generation. Flow matching provides flexibility in model design; however, the framework is predicated on the assumption of continuously-valued data. 3D de novo molecule generation requires jointly sampling continuous and categorical variables such as atom position and atom type. We extend the flow matching framework to categorical data by constructing flows that are constrained to exist on a continuous representation of categorical data known as the probability simplex. We call this extension SimplexFlow. We explore the use of SimplexFlow for de novo molecule generation. However, we find that, in practice, a simpler approach that makes no accommodations for the categorical nature of the data yields equivalent or superior performance. As a result of these experiments, we present FlowMol, a flow matching model for 3D de novo generative model that achieves improved performance over prior flow matching methods, and we raise important questions about the design of prior distributions for achieving strong performance in flow matching models. Code and trained models for reproducing this work are available at https://github.com/dunni3/FlowMol.},
	language = {en},
	urldate = {2025-12-23},
	publisher = {arXiv},
	author = {Dunn, Ian and Koes, David Ryan},
	month = apr,
	year = {2024},
	note = {arXiv:2404.19739 [q-bio]},
	keywords = {Computer Science - Machine Learning, Quantitative Biology - Biomolecules},
	file = {PDF:/Users/shreyas/Zotero/storage/FN5X4S7Z/Dunn and Koes - 2024 - Mixed Continuous and Categorical Flow Matching for 3D De Novo Molecule Generation.pdf:application/pdf},
}
